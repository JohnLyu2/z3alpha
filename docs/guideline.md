# Guidelines for Preparing SMT-COMP'25

## Summary of Important Notes

* Download benchmarks from the SMT-LIB'25 Zenodo repo: https://zenodo.org/records/15493090**
* Make sure using the Z3 latest stable version, **Z3-4.15.0**: https://github.com/Z3Prover/z3/releases/tag/z3-4.15.0, for both synthesis and evaluaiton.
* Syntheize config json:
    - `timeout` (`s1config`): 30s
    - `sim_num` (`s1config`): 600
    - `ln_strat_num`: 4
    - Create a training instance set (`bench_dirs` in `s1config`) with appropriate size and difficulty (see [Training Dataset Preparation](#training-dataset-preparation) below)
* Use 3min (180s) as the evaluation time limit.


## Training Dataset Preparation

### SMT-LIB Benchmark Downloading

Download benchmarks from the SMT-LIB'25 Zenodo repo: https://zenodo.org/records/15493090.
You may use the downloading script at `scripts/smtlib25_download.sh` 
(Usage:`scripts/smtlib25_download.sh <logic-name> [<save-path>]`)

### Size of the Training Instance Set

**(TBD)** We will use a 30-second time limit (for each instance-solver-pair execution)
and run simulations for 600 times when synthesizing strategies. 
Depending on the computation resources (e.g., #cores), we can decide how many instances we want to include in the training set for each logic.

For example, I use a machine with 64 cores (nodes at Narvel, Compute Canada)
and run the evaluator with 64 instances in parallel.
A training set of size 320 is reasonable, since it will be take 
30 x (320/64) x 600 = 90000s = 25hr at most (in practice it will be much faster, since many instances are easy). 

### Sample from the Logic Benchmarks

If the total size of the logic is less than or slightly more than the required size, you can include all the benchmarks in the logic as the training set. 

Otherwise, you can use `scripts/sampling_benchmarks.py` to sample a training set (with symbolic links). The script performs weighted random sampling from benchmarks that take more than 1 second to solve, with a bias towards unsolved instances.

Usage:
```bash
python scripts/sampling_benchmarks.py \
    --performance-path /path/to/performance/results.csv \
    --target-dir /path/to/generated/training/set/directory \
    --target-size <desired_training_size>
```

Parameters:
- `--performance-path`: Path to the CSV file containing benchmark solving results, e.g., `data/ijcai24/results/QF_BV/core/results/raw_data/z3.csv` as generated by `scripts/exp_tester.py`
- `--target-dir`: Path to the directory where the training set will be generated
- `--target-size`: Number of benchmarks to include in the training set

Note that `sampling_benchmarks.py` takes a performance csv as input. 
Such file is generated by running `scripts/exp_tester.py` on the all benchmarks. 
Let's use 180s as the time limit in this evaluation.

### Example of Generating a Traning Set

 1. Generate the performance csv by running:

 ```bash
 python scripts/exp_tester.py data/smtcomp25/configs/eval/qfnra.json
 ```

The generated csv is saved at `data/smtcomp25/results/QF_NRA/z3.csv`.

 2. Create a trainig instance set at `data/smtcomp25/train_benchmarks/QF_NRA`:

 ```bash
python scripts/sampling_benchmarks.py \
    --performance-path data/smtcomp25/results/QF_NRA/z3.csv \
    --target-dir data/smtcomp25/train_benchmarks/QF_NRA \
    --target-size 320
```

## Z3alpha Environment Setup

**About Z3**

Make sure you are using Z3-4.15.0. 

By default, the Z3alpha synthesis code calls Z3 by the command `Z3` in the system PATH. 
If your Z3 executable is not in the PATH, or the default one is not the right version, you can speficy the Z3 binary's path using `z3path` in the synthesis configuration JSON file.

**Install Z3alpha**

```bash
pip install -e .
```

## Synthesize Strategies

We synthesize one parallel strategy for each logic. The synthesis script is located at `z3alpha/scripts/synthesize_para.py` and takes a configuration JSON file as input.

### Running Synthesis

```bash
python z3alpha/scripts/synthesize_para.py data/smtcomp25/configs/synthesis/qfnra.json
```

### Configuration JSON

The configuration JSON file (e.g., `data/smtcomp25/configs/synthesis/qfnra.json`) contains all parameters for the synthesis process. Here are the key parameters to configure:

* `logic`: The SMT-LIB logic name (e.g., "QF_NRA")
* `batch_size`: Number of parallel instances to run (set to match your CPU core count)
* In `s1config`
  * `bench_dirs`: Path to your training set directory
  * `sim_num`: Number of simulations (use 600)
  * `timeout`: Time limit per instance in seconds (use 30)
* `ln_strat_num`: Number of linear strategies to run in parallel (use 4)

### Output

The script saves the sysnthesis results (e.g., the resulting strategy) in a folder named by the starting time stamp under `experiments/synthesis/`.

**Please also save the log printed to the terminal and move it to the result folder.** 

### MultiProcess Strategy Evaluation

To evaluate the performance of a synthesized parallel strategy on a benchmark set using the multiprocess evaluator, use the script `z3alpha/multiprocess_evaluator.py`.

#### Example Usage

```bash
python z3alpha/multiprocess_evaluator.py \
  --solver z3 \
  --cpus-per-task 4 \
  --memory-per-task 1024 \  # (Optional) Memory in MB per task
  --benchmark-dir data/ijcai24/benchmarks/samples \
  --timeout 30 \
  --output path/to/output/results.csv \
  --strategy "a string containing the strategy" \
  --monitor-output path/to/output/monitor  # (Optional) Directory to store CPU and memory usage logs
```

#### Notes

- **Memory Allocation**:  
  If `--memory-per-task` is not specified, total available memory will be equally divided among tasks.

- **Monitoring**:  
  If `--monitor-output` is not specified, CPU and memory usage logs will not be generated.

- **CPU Allocation**:  
  Set `--cpus-per-task` equal to the number of parallel strategies used (e.g., 4 for SMTCOMP-25 format) to ensure each strategy runs on a dedicated core.